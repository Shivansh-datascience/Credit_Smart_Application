# Pinecone Vector Database Configuration
pinecone:
  api_key: "${PINECONE_API_KEY}"  # Set via environment variable from .env
  index_name: "credit-policy-index"  # Your Pinecone index name
  namespace: "credit-policy-index-1"  # Namespace within the index
  host: "https://credit-policy-index-wnvzyhf.svc.aped-4627-b74a.pinecone.io"
  region: "us-east-1"
  dimension: 384  # Embedding dimension (for sentence-transformers/all-MiniLM-L6-v2)
  metric: "cosine"  # Similarity metric (cosine, euclidean, dotproduct)

# LangChain Configuration
langchain:
  embeddings:
    model: "sentence-transformers/all-MiniLM-L6-v2"  # HuggingFace embedding model
    cache_folder: "./models"  # Local cache for embeddings
  retriever:
    search_type: "similarity"  # Type of search (similarity, mmr, etc.)
    k: 3  # Number of documents to retrieve
    fetch_k: 20  # Fetch more before filtering (for MMR)

# LLM Configuration (DeepSeek)
llm:
  provider: "deepseek"  # LLM provider
  model: "deepseek-chat"  # Model name
  api_key: "${DEEPSEEK_API_KEY}"  # Set via environment variable
  temperature: 0.7  # Creativity level (0-1)
  max_tokens: 1024  # Maximum response length
  top_p: 0.9  # Nucleus sampling

# RAG Chain Configuration
rag:
  system_prompt: "You are a helpful assistant for credit scoring and financial analysis."
  context_window: 3  # Number of retrieved documents to use
  output_format: "text"  # Response format (text, json, markdown)
  include_sources: true  # Include source documents in response

# MongoDB Configuration (for storing conversations/metadata)
mongodb:
  uri: "mongodb://localhost:27017"  # MongoDB connection string
  database: "credit_scoring_db"
  collections:
    conversations: "chatbot_conversations"
    documents: "indexed_documents"

# FastAPI Server Configuration
server:
  host: "0.0.0.0"  # Server host
  port: 8001  # Server port (different from auth_service)
  debug: true  # Debug mode (false in production)
  title: "RAG Chatbot API"
  version: "1.0.0"
  description: "Credit Scoring RAG Chatbot with LangChain and Pinecone"

# CORS Configuration
cors:
  allow_origins:
    - "http://localhost:3000"
    - "http://localhost:5173"
    - "http://localhost:8080"
    - "http://localhost:4200"
  allow_credentials: true
  allow_methods:
    - "GET"
    - "POST"
    - "PUT"
    - "DELETE"
  allow_headers:
    - "*"

# Logging Configuration
logging:
  level: "INFO"  # Logging level (DEBUG, INFO, WARNING, ERROR)
  file: "chatbot_service.log"  # Log file path
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Document Processing Configuration
document_processing:
  chunk_size: 1000  # Size of text chunks for indexing
  chunk_overlap: 200  # Overlap between chunks
  supported_formats:
    - "pdf"
    - "txt"
    - "docx"
    - "csv"
  max_file_size_mb: 50  # Maximum file size for upload

# Caching Configuration
cache:
  enabled: true  # Enable response caching
  ttl_seconds: 3600  # Cache time-to-live (1 hour)
  redis:
    host: "localhost"
    port: 6379
    db: 1  # Different DB from auth service

# Rate Limiting Configuration
rate_limiting:
  enabled: true
  requests_per_minute: 60  # Max requests per minute per user
  burst_limit: 10  # Burst limit

# LangSmith Tracing (for debugging)
langsmith:
  enabled: true
  api_key: "${LANGSMITH_API_KEY}"
  project: "credit-scoring-rag"
